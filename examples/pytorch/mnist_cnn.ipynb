{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_pytorch = datasets.MNIST(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tensor = torch.nn.functional.one_hot(mnist_pytorch.targets).to(dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = mnist_pytorch.data.to(dtype=torch.float32).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ds = torch.utils.data.TensorDataset(input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = torch.utils.data.random_split(input_ds, [0.8, 0.2])\n",
    "train_ds, val_ds = torch.utils.data.random_split(train_ds, [0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 512\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=mini_batch_size, shuffle=True, drop_last=False)\n",
    "valid_dl = torch.utils.data.DataLoader(val_ds, batch_size=mini_batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, padding=2),\n",
    "            torch.nn.BatchNorm2d(10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=10, out_channels=25, kernel_size=5),\n",
    "            torch.nn.BatchNorm2d(25),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=25, out_channels=40, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(40),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=40, out_channels=30, kernel_size=3, padding=1),\n",
    "            torch.nn.BatchNorm2d(30),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(750, 300),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.4),\n",
    "            torch.nn.Linear(300, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.4),\n",
    "            torch.nn.Linear(100, 10)\n",
    "        )\n",
    "\n",
    "        # historical architecture\n",
    "        self.LeNet = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.AvgPool2d(2, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.AvgPool2d(2, stride=2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(400, 120),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(120, 84),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.cnn(X)\n",
    "        # X = self.LeNet(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of trainable model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344731"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, optimizer, train_dl, valid_dl=None):\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        # loop over mini-batches\n",
    "        for X_mb, y_mb in train_dl:\n",
    "            y_hat = model(X_mb)\n",
    "\n",
    "            loss = loss_func(y_hat, y_mb)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_loss = sum(loss_func(model(X_mb), y_mb) for X_mb, y_mb in train_dl)\n",
    "            valid_loss = sum(loss_func(model(X_mb), y_mb) for X_mb, y_mb in valid_dl)\n",
    "        print('epoch {}, training loss {}'.format(epoch + 1, train_loss / len(train_dl)))\n",
    "        print('epoch {}, validation loss {}'.format(epoch + 1, valid_loss / len(valid_dl)))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    print('Finished training')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, training loss 0.06906738132238388\n",
      "epoch 1, validation loss 0.070371113717556\n",
      "epoch 2, training loss 0.044127319008111954\n",
      "epoch 2, validation loss 0.054086655378341675\n",
      "epoch 3, training loss 0.03700147569179535\n",
      "epoch 3, validation loss 0.051151443272829056\n",
      "epoch 4, training loss 0.02821594476699829\n",
      "epoch 4, validation loss 0.049353744834661484\n",
      "epoch 5, training loss 0.02262027934193611\n",
      "epoch 5, validation loss 0.045449744910001755\n",
      "epoch 6, training loss 0.03411605954170227\n",
      "epoch 6, validation loss 0.05846225842833519\n",
      "epoch 7, training loss 0.05333656445145607\n",
      "epoch 7, validation loss 0.07480274885892868\n",
      "epoch 8, training loss 0.020876292139291763\n",
      "epoch 8, validation loss 0.04985110089182854\n",
      "epoch 9, training loss 0.011253946460783482\n",
      "epoch 9, validation loss 0.03753636032342911\n",
      "epoch 10, training loss 0.011291625909507275\n",
      "epoch 10, validation loss 0.03962769731879234\n",
      "epoch 11, training loss 0.00722927413880825\n",
      "epoch 11, validation loss 0.03305156156420708\n",
      "epoch 12, training loss 0.007816819474101067\n",
      "epoch 12, validation loss 0.03896044194698334\n",
      "epoch 13, training loss 0.008640095591545105\n",
      "epoch 13, validation loss 0.04144663363695145\n",
      "epoch 14, training loss 0.010333449579775333\n",
      "epoch 14, validation loss 0.03806452825665474\n",
      "epoch 15, training loss 0.0061139268800616264\n",
      "epoch 15, validation loss 0.04017750546336174\n",
      "epoch 16, training loss 0.0045229787938296795\n",
      "epoch 16, validation loss 0.037328772246837616\n",
      "Early stopping\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "trained_model = fit(epochs, model, optimizer, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping.load_best_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(ds, model):\n",
    "    with torch.no_grad():\n",
    "        preds = model(ds[:][0]).cpu()\n",
    "\n",
    "    # take output node with highest probability\n",
    "    yhat = np.argmax(preds, axis=1)\n",
    "    y = ds[:][1].cpu()\n",
    "\n",
    "    # from one-hot back to labels\n",
    "    y = torch.argmax(y, dim=1)\n",
    "\n",
    "    metric = MulticlassAccuracy()\n",
    "\n",
    "    metric.update(yhat, y)\n",
    "    return metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9989)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_ds, trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9913)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(test_ds, trained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
